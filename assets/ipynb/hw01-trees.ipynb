{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LX 496/796  Introduction -- Parsing and context free grammars\n",
    "\n",
    "### Due Monday at 11:59 PM in Gradescope (with grace period of 6 hours)\n",
    "\n",
    "In this second homework, you will become familiar with creating context free grammars in NLTK.  Also, parsing, drawing, and traversing syntactic trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with a context-free grammar ###\n",
    "\n",
    "We'll now use NLTK to do a little bit of actual theoretical linguistics.\n",
    "This is at least partly based on chapter 8 of the NLTK book.\n",
    "\n",
    "As a first step, we're going to create a context-free grammar to play with.\n",
    "It is possible to do this by putting your grammar in a separate file and then loading it, but\n",
    "to keep things easier for handing in, we'll just do everything in the notebook\n",
    "\"in-line.\"\n",
    "\n",
    "First, the standard `import nltk` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we will make a trivial context free grammar.  It will only be able to parse the sentence \"I left\" and will do so by saying that sentences are made of a NP, \"I\", and a VP, \"left\".  We'll define it, draw a tree with it, and then move on to more elaborate grammars.\n",
    "\n",
    "The command below defines a string containing three lines, each line with a rule of our context free grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramileft = \"\"\"\n",
    "S -> NP VP\n",
    "NP -> 'I'\n",
    "VP -> 'left'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the string, we feed it to NLTK to turn it into a proper Context Free Grammar object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgileft = nltk.CFG.fromstring(gramileft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Convention*: In this notebook, we will name the strings that specify a context free grammar `gram...` and the context free grammar object that NLTK creates from them `cfg...`, as above, for the \"ileft\" grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it worked by telling this grammar object to list the things it can produce.  It should give you a list of the rules back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgileft.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the sentence we would like to have our grammar parse.  We will put this sentence in the variable `raw` (for raw text).  Then, we will define `sent` (sentence) as being the list of words in our raw text, by using `.split()` to split on \"whitespace\" and collect the results in a list.  This process of splitting a text into words like this is called \"tokenizing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"I left\"\n",
    "sent = raw.split()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now ask NLTK to make a parser just for our little toy grammar.  The parser type will be a recursive descent parser, tailored to parse based on the `cfgileft` grammar.  We will call our parser `parser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.RecursiveDescentParser(cfgileft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our parser, we can tell it to parse something, specifically `sent`.  What we get back is a \"generator\", which is an object that generates the next tree until we are out of possible parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treegen = parser.parse(sent)\n",
    "print(treegen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in class, when you use a generator, it gets \"consumed.\"  More technically, the generator knows how to move to the next thing in the list of things it is going to generate, but it does not know how to go back.  So, it can only move forward, and so if you ask it to keep generating more trees until it runs out, it will then be out, and asking it again will not yield anything.  The command below shows this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tree(s):')\n",
    "for t in treegen:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do it a second time, there are no trees left, so we get no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tree(s):')\n",
    "for t in treegen:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to get the trees back is to redefine the generator.  So, we'll do that now, but then we'll collect the generated trees into a list of trees.  Once they are stored in the list, we can refer to them as many times as we'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treegen = parser.parse(sent)\n",
    "trees = list(treegen)\n",
    "print(trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's draw our tree.  This will probably cause a little window to pop up somewhere, with the tree in it.  You will need to close that window with the tree in it in order to proceed further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing a more complex phrase structure grammar ###\n",
    "\n",
    "We can start with the basic \"park grammar\" that comes from the book (so named I guess because it handles sentences that contain \"in the park\").\n",
    "\n",
    "The first part of the grammar specification below generally is defining the possible structures of sentences in general, and then the latter part of the grammar specification is defining the words.  It is possible to use the pipe character (`|`) to separate disjunctive options (essentially like a logical \"or\").  The grammar given below is what we want.  It shows that there are three verbs, four prepositions, four determiners, four nouns.  It shows that verbs can either be followed by an NP (the object) or an NP and a PP (an object and a prepositional indirect object).  Prepositions are followed by an object.  And NPs can either be a name, or be a Det plus an N and optionally plus a prepositional phrase.\n",
    "\n",
    "```python\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> 'saw' | 'ate' | 'walked'\n",
    "NP -> 'John' | 'Mary' | 'Bob' | Det N | Det N PP\n",
    "Det -> 'a' | 'an' | 'the' | 'my'\n",
    "N -> 'man' | 'dog' | 'cat' | 'telescope' | 'park'\n",
    "P -> 'in' | 'on' | 'by' | 'with'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "\n",
    "Put this grammar's specification in a string called `grampark`, following the definition of `gramileft` above.\n",
    "\n",
    "> This is not supposed to be hard.  You can copy the grammar in the cell above, and paste it into a definition of a multi-line string called `grampark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1: define a multi-line string called grampark with the grammar shown above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n",
    "\n",
    "Have NLTK build a CFG object out of this specification, call it `cfgpark`, following the model of creating `cfgileft` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2: define a CFG called cfgpark from grampark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In preparation for the next task, we will parse the sentence \"Bob saw a telescope on a dog\" and count how many parses it has.  (It has 2, because it is two-ways ambiguous.)  This serves as an example of what you will do in Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.RecursiveDescentParser(cfgpark)\n",
    "raw = \"Bob saw a telescope on a dog\"\n",
    "sent = raw.split()\n",
    "treegen = parser.parse(sent)\n",
    "trees = list(treegen)\n",
    "print(\"{}. {} parse(s)\".format(raw, len(trees)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "\n",
    "Show how many parses `cfgpark` can generate for each of the following sentences:\n",
    " - Mary saw Bob\n",
    " - my dog saw a cat in the park\n",
    " - a dog ate John\n",
    " - Mary saw\n",
    "\n",
    "To do this, follow the process we used earlier.  Specifically, you'll need to have NLTK make a parser object for you, then tell that parser object to parse each of the (tokenized) sentences above, and then print the length of the list of parses each sentence gets.\n",
    "\n",
    "> You should get 1, 2, 1, and 0 parses for the four sentences above, respectively, if it worked.\n",
    ">\n",
    "> You can of course follow the logic of the code above, that is why it is there.\n",
    "> But you do not need to redefine `parser`, since it is already defined by the code above\n",
    "> and has not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3. Parse the sentences above and print how many parses each gets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n",
    "\n",
    "Create a grammar specification called `gramparkadj` that extends `grampark` to allow for adjectives.\n",
    "Specifically, the goal is for it to be able to handle\n",
    "\"my annoying little dog saw a cat in the lovely park\"\n",
    "and\n",
    "\"a vicious dog ate John.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The chapter (in NLTK, chapter 8) pretty much goes over this, around example 3.3, though it is quite concise there.\n",
    "> When you think about the structure of \"my annoying little dog\", we have a determiner (*my*),\n",
    "> two adjectives (*annoying* and *little*), and then the head noun (*dog*).  So, in addition to\n",
    "> `NP -> Det N` (which we need to keep so we can still get \"a dog\"), we need an `NP` rule that\n",
    "> allows for one or two adjectives between `Det` and `N`.  One could do this either by just adding\n",
    "> two rules (one that has one adjective, one that has two), or by adjusting the system to allow\n",
    "> for any number of adjectives between Det and N.  This choice is kind of based on what the goals\n",
    "> are; if you just want to cover the sentences, it might be simplest to add a one-adjective rule and\n",
    "> a two-adjective rule.  But since we know English can sometimes have three adjectives, or more even,\n",
    "> we might also adjust the rules in a more general way to allow any number of adjectives between Det and\n",
    "> N.  One way to do this more generally would be to create a constituent that corresponds to what we would\n",
    "> have called \"N-bar\" in Intro to Linguistics.  That's what the book does, but it uses \"Nom\" for what\n",
    "> we would have called \"N-bar\".\n",
    "> \n",
    "> It's probably better to try for the more general case, so follow example 3.3 in the book, and make it so that\n",
    "> NPs can have a `Det` and a `Nom` (again, that's basically N-bar), and a `Nom` can have an `Adj` and a `Nom`\n",
    "> (which is a recursive rule, allowing for any number of adjectives), or a `Nom` can be a `N`.\n",
    "> \n",
    "> So, you want to add a rule like `Adj -> \"annoying\" | \"little\" | \"lovely\" | \"vicious\"` so that it\n",
    "> covers the adjectives we need, and then a `Nom -> Adj Nom` rule to allow the iterative\n",
    "> attachment of adjectives to \"N'\", and then revise the `NP` rule so it expands to `Det`\n",
    "> and `Nom` (rather than to `Det` and `N`), and add one more `Nom` rule that allows it to be\n",
    "> rewritten just as `N` (without any further adjectives).\n",
    ">\n",
    "> To define the multi-line string `gramparkadj`, you can just copy and paste the `grampark` string and then\n",
    "> modify it as needed to add support for adjectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4: Define a multi-line string gramparkadj that specifies the grammar, extended to handle adjectives\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build the CFG object from this description, and have NLTK make a parser based on that CFG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgparkadj = nltk.CFG.fromstring(gramparkadj)\n",
    "parser = nltk.RecursiveDescentParser(cfgparkadj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it worked, the following code should succeed.  (Look through the code to see what it is doing,\n",
    "but you should get the \"Success!\" message.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'Mary saw a lovely cat'\n",
    "sent = raw.split()\n",
    "treegen = parser.parse(sent)\n",
    "trees = list(treegen)\n",
    "if len(trees) > 0:\n",
    "    print('\\o/ Success! The sentence was parsed.')\n",
    "else:\n",
    "    print(\"D'oh! Something is amiss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that can take a\n",
    "string, break it up into words, parse it, and return the trees.  That will make\n",
    "it simpler to deal with this procedure.\n",
    "Take a moment to understand the code, and see how it relates to what we just did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trees(raw, cfg):\n",
    "    sent = raw.split()\n",
    "    parser = nltk.RecursiveDescentParser(cfg)\n",
    "    treegen = parser.parse(sent)\n",
    "    trees = list(treegen)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can do the same check we did above, but making use of our `get_trees()` function.  You should still get the \"Success!\" message.  Look it over to understand what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = get_trees('Mary saw a lovely cat', cfgparkadj)\n",
    "if len(trees) > 0:\n",
    "      print('\\o/ Success! The sentence was parsed.')\n",
    "else:\n",
    "    print(\"D'oh! Something is amiss.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5\n",
    "\n",
    "Show how many parses the grammar specified by `gramparkadj` gives (as you did in Task 3) for the following sentences:\n",
    " - my annoying little dog saw a cat in the lovely park\n",
    " - a vicious dog ate John\n",
    " - a man walked in the park\n",
    "\n",
    "> You should get 2, 1, and 0, respectively, if it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5: Parse the sentences above with cfgparkadj and print how many parses each gets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6\n",
    "\n",
    "This grammar will give you nothing for \"a man walked in the park\".  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 6** (markdown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traversing trees, finding subjects and objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will try to find the subject of a sentence.  Descriptively, the subject\n",
    "of a sentence is the NP that is a daughter of S.  Ultimately, in this grammar we have built\n",
    "so far, it's always going to be in the same place, but let's explore this a little bit anyway.\n",
    "\n",
    "We can take a tree that our parser has found for us and break it up into subtrees, which\n",
    "will allow us to isolate NP-daughter-of-S pretty easily.  So, for the \"John saw Mary\" tree,\n",
    "what `get_trees(\"John saw Mary\")` gives us back is a list of parses (containing just one\n",
    "element), so let's look at that tree.  We'll name it `tree`.  Good day to you, `tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = get_trees(\"John saw Mary\", cfgparkadj)[0]\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ask a thing of the `Tree` type to give you `subtrees()` it will go through a tree and give you\n",
    "a list of all the subtrees contained in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in tree.subtrees()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we want to find the \"NP daughter of S\", we look for a subtree whose label is \"S\"\n",
    "and for which the label of one of the contained Tree nodes is \"NP\".\n",
    "\n",
    "There are not many subtrees that have the label \"S\".  In fact, there's just the one, and it's\n",
    "the whole tree.  But we can still find it in a more general way, by adding an `if` clause\n",
    "to the list comprehension we used to display them above.  To start with an example slightly more interesting than \"S\", here is a list comprehension that filters the trees to give us just the \"NP\" subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in tree.subtrees() if s.label() == \"NP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to find the \"S\" subtree(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in tree.subtrees() if s.label() == \"S\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find the daughter of that node S whose label is \"NP\".  What are the daughters of\n",
    "S?  A `Tree` basically behaves like a list, so we can count the number of daughters with `len(tree)`\n",
    "and go through them with `for n in tree`.  If there are two, `tree[0]` will be the left one, and\n",
    "`tree[1]` will be the right one.\n",
    "\n",
    "This is illustrated below.\n",
    "First, we make a list of the subtrees that have S as the label.\n",
    "There's really just going to be one in this case\n",
    "(though if the tree were complex enough to have one S embedded within another we might have more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snodes = [s for s in tree.subtrees() if s.label() == \"S\"]\n",
    "snode = snodes[0]\n",
    "print(snode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subtree we called `snode` has two elements, because it has two immediate daughters (NP and VP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(snode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left daughter of S is `snode[0]`, and that's the subject, which contains only the N \"John\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snode[0])\n",
    "len(snode[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right daughter of S is the VP, addressed as `snode[1]`.  It has two elements, the V and the NP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snode[1])\n",
    "len(snode[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to retrieve the verb (which is the left daughter of the right daughter of S),\n",
    "there are three equivalent ways we can address it.\n",
    "\n",
    "We could (a) explicitly request the 0th element of the\n",
    "1st element of the `snode` Tree (that is, the left daughter of the right daughter of S),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snode[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or we can (b) compress that into a tuple (this is just a notation that Python allows for) and ask for the `(1, 0)`th element (still means the left\n",
    "daughter of the right daughter of S)... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snode[(1,0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and it's even possible (though kind of confusing I think)\n",
    "to leave the parentheses off the tuple when it is within square brackets.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snode[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...I think probably the `[1][0]` version is the easiest to understand of those three.\n",
    "\n",
    "So, this is how you navigate subtrees.  If we have `snode` set to be an \"S\"-labeled Tree,\n",
    "as we did above, we can cycle through its daughters and find the one that has an \"NP\" label,\n",
    "and that will be the NP daughter of S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d for d in snode if d.label() == \"NP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually combine these in a single (though complicated) list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d for n in tree.subtrees() if n.label() == 'S' for d in n if d.label() == 'NP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This takes the NP-finder above, but adds in the computation of `snodes` as well. Notice the order.  We're making a list of `d`s, which are the daughters of `snode`. So we continue to start with `[d for...` but then we are going to find the `snodes` first, and then the daughters of those once we have an `snode`.  So, we continue with `n in tree.subtrees() if n.label() == \"S\"` meaning that `n` is going to be a subtree with label \"S\" that we want to then check the daughters of.  So, then we go through the daughters with `for d in n if d.label() == \"NP\"`.  Put together, it looks as given above.\n",
    ">\n",
    ">Saying it again/slightly differently: To read this, start reading after `[d for` for the moment: \"For each node `n` in whose label is `\"S\"`, and for each node `d` in `n` whose label is `\"NP\"`, add `d` to the list\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7\n",
    "\n",
    "Understand how that complex list comprehension works.\n",
    "It's not simple.  Even I have to stare at these for a little while before I get it.\n",
    "Re-read the explanation above a couple of times and keep in mind what this is supposed\n",
    "to be accomplishing.\n",
    "Then, **convince yourself\n",
    "that you have succeeded\n",
    "by changing it so that it finds the object instead.**\n",
    "(What we did above is find the subject, which is the\n",
    "NP daughter of S.  So, how do we characterize the object?  Use the technique above to find it.\n",
    "The answer should be \"Mary\", right?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7: Revise the list comprehension above to find the object instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's enhance the grammar by adding the ability to embed clauses, like in\n",
    "\"Bob thought that John saw Mary\" and \"Bob said that John saw Mary\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 8\n",
    "\n",
    "Enhance the grammar so that it can parse \"Bob thought that John saw Mary\" and \"Bob said that John saw Mary\".  Call the (multi-line string) specification of the new grammar `gramcomp` and have NLTK create a CFG object from it called `cfgcomp`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The idea here is to add still more to `gramparkadj` from before.  We need to add the verbs `\"said\"` and `\"thought\"` at least, and the\n",
    "> complementizer `\"that\"`.\n",
    "> \n",
    "> Consider that, although \"said\" and \"thought\" are verbs, they do not take NP objects.\n",
    "> So they're a different kind of a verb.  They are in the *category* of \"verb\" but they\n",
    "> are a sub-type, a *sub-category* of verb.  So, we do not simply want to add something\n",
    "> like `... | \"thought\" | \"said\"` to the `V ->` line.  We need a different kind of verb,\n",
    "> the book calls them \"Sentential verbs\" and gives them a label of `SV`, so we can follow\n",
    "> that here.\n",
    "> \n",
    "> If the sentential verbs are category `SV`, we still want to be able to form a `VP`\n",
    "> out of a `SV` and its complement.  So, we need to add that as an option to the `VP`\n",
    "> rules.  In order to do this, we also need to figure out what the complement of such\n",
    "> a verb is.\n",
    "> \n",
    "> This is simplifying things, but let's assume that the complement of \"thought\" is\n",
    "> basically always `that S` --- so \"that\" is a complementizer, we can call it category\n",
    "> `C` and we can form a `CP` from `C` and `S`.  Then `SV` type verbs will have a\n",
    "> `CP` as their complement.  It's pretty close to what you'd have seen in Intro\n",
    "> syntax, apart from probably calling `S` \"IP\" instead.\n",
    "> \n",
    "> TL;DR: You will want to add rules with left sides being CP, C, SV, and another with VP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8: Define gramcomp and cfgcomp (allowing sentential complements of thought and said)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 9\n",
    "\n",
    "Give trees for:\n",
    " - Bob said that John saw Mary in the park\n",
    " - the annoying man thought that Bob said that my dog saw a vicious cat in the park\n",
    " \n",
    "You can use the text representations of the trees that `print(tree)` provides.  Also: don't forget that we defined `get_trees(raw, cfg)` above, so you can just use that to get the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9: Print trees for the sentences above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 10\n",
    "\n",
    "Find the subjects of those sentences using our subject-finding procedure\n",
    "from before.\n",
    "It should be \"Bob\" and \"John\" in one case, \"the annoying man\", \"Bob\", and \"my dog\" in the other.\n",
    "(Also, it is ok if your subjects when printed look like `[Tree('NP', ['Bob'])]` rather than just \"Bob\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10: Find (and print) the subjects of the sentences above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 11\n",
    "\n",
    "Find the objects of those sentences using our\n",
    "object-finding procedure from before.  (Should be \"Mary\" in one case, \"a vicious cat (in the park)\" in the other.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find (and print) the objects of the sentences above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative clauses\n",
    "\n",
    "A relative clause is something like \"who saw Mary\" in \"the man who saw Mary\". \n",
    "It is formed by adding a *wh*-question to a noun, more or less.  So the referent\n",
    "of \"the man who saw Mary\" is the individual that is a man, and also the answer\n",
    "to the question \"Who saw Mary?\". \n",
    "\n",
    "Suppose we want our parser to recognize \"the man who saw Mary\" as an NP.\n",
    "\n",
    "It can already recognize \"the man\" and \"the man in the park\", so we can\n",
    "simply add an extra option for the `NP` rule to allow for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \"the man who saw Mary\", it seems like \"who\" is basically the\n",
    "subject of \"saw\".  So, \"who saw Mary\" is a special kind of sentence\n",
    "with \"who\" as the subject.  Let's define this kind of special case\n",
    "by, first, making \"who\" a special kind of NP, and then making a\n",
    "relative clause be a special kind of sentence with \"who\" as its\n",
    "subject.\n",
    "\n",
    "So, we can add these to the grammar (`RP` is the relative pronoun, `RC` is the relative clause, which is a relative pronoun and a verb phrase, and we add one more kind of `NP` that has a `RC` attached)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramrcsub = gramcomp + \"\"\"\n",
    "RP -> 'who'\n",
    "RC -> RP VP\n",
    "NP -> Det Nom RC\n",
    "\"\"\"\n",
    "\n",
    "cfgrcsub = nltk.CFG.fromstring(gramrcsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = get_trees(\"the man who saw Mary saw Bob\", cfgrcsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trees[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this opportunity to look at the structure we get, in tree form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's another form a relative clause can take, though.  You can also say\n",
    "\"the man who Mary saw saw Bob\".  What's different here is that \"who\" is now \n",
    "playing the role of the object, rather than the subject.\n",
    "\n",
    "The relative pronoun \"who\" generally corresponds to a gap\n",
    "in the sentence.  We didn't notice the gap before, when the gap was in the subject\n",
    "position, but it's obvious\n",
    "when the gap is in the object position.  These relative clauses are, again,\n",
    "basically *wh*-questions, and the normal way *wh*-questions are formed is to \n",
    "move the *wh*-word to the front of the clause.\n",
    "\n",
    "And this is where parsing becomes difficult, when things move around in a sentence.\n",
    "\n",
    "Let's try a kind of a hack to make this work.\n",
    "\n",
    "For any transitive verb (\"saw\", \"ate\", and \"walked\" in our grammar), there is the\n",
    "version we already have, which form a VP with their object NP.  If any of these appear\n",
    "in an \"object relative\", then the object NP will be \"missing\".  So, let's make a version\n",
    "of the VP that has a \"**gap**\".  That is, we will define `VPG` (VP-gap) to be just `V` rather than \n",
    "`V NP`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below will give us a list of all the rules in `cfgrcsub` that have `VP` on the left side. For any of these that have `V NP` in them, we want to make a `VPG` version (a VP with an object gap) with the `NP` omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in cfgrcsub.productions() if str(p.lhs()) == 'VP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramvpg = gramrcsub + \"\"\"\n",
    "VPG -> V\n",
    "VPG -> V PP\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't used `VPG` yet in the grammar apart from defining it.  But conceptually,\n",
    "what we want is that `VPG` should be available in a relative clause where the\n",
    "object is missing.  So, we want to redefine `RC`, in a form that's closer to what\n",
    "we believe the structure of these is.  So replace the `RC` definition you added\n",
    "before with this:\n",
    "```python\n",
    "RC -> RP SWOG\n",
    "SWOG -> NP VPG\n",
    "```\n",
    "The idea here is that `SWOG` (sentence-with-object-gap) is like a regular `S` but\n",
    "has a `VP` with an object gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this replacement, it's probably easier to edit the whole specification.  So, let's print out the multi-line string that specifies our most recent version of the grammar, and then afterwards you can copy and paste that into the next version of the grammar, making the changes just mentioned (adding `SWOG` in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gramvpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 12\n",
    "\n",
    "Define a multi-line string `gramrcobj` that specifies a grammar that can handle object relative clauses, by copying the grammar above and then adding the modifications for `SWOG` discussed above that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 12: define gramrcobj as above but with modifications for SWOG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you did that right, we should now get a tree below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgrcobj = nltk.CFG.fromstring(gramrcobj)\n",
    "trees = get_trees(\"the man who Mary saw in the park saw Bob\", cfgrcobj)\n",
    "print(trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw it graphically as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the change above broke our ability to parse the subject relative \"the man who saw Mary\", however.  (Because we replaced the rule that we used for that.)\n",
    "\n",
    "With our new understanding of relative clauses (where there is always going to be a gap, even for subject relatives) the gap in \"the man who saw Mary\" must actually\n",
    "be the subject of \"saw\".  So, let's add some rules to get subject relatives as well, analogous to what we added for object relatives.\n",
    "\n",
    "We'll start by adding `RC -> RP SWSG` to the grammar (`SWSG` being intended to mean \"sentence-with-subject-gap\").\n",
    "So, there are now two kinds of relative clause the grammar can handle.  Both start with the `RP` \"who\",\n",
    "and one continues with `SWSG` (an `S` but missing the subject), and the other continues with a `SWOG`\n",
    "(an `S` but missing the object).  We still need to define `SWSG`.  What should it be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 13\n",
    "\n",
    "Add a definition of `SWSG` into the grammar.  This time, slightly less hand-holding, but if you've been following along properly, it should be fairly clear what you want to add.  You should need to add two rules, one with `RC` as its left hand side, and one with `SWSG` as its left hand side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 13: define gramrc as being the multi-line string with modifications for SWSG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you made the right addition, we should be able to parse \"the man who saw Mary saw Bob\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgrc = nltk.CFG.fromstring(gramrc)\n",
    "trees = get_trees(\"the man who saw Mary saw Bob\", cfgrc)\n",
    "print(trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again we can look at the tree graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 14\n",
    "\n",
    "Draw trees of:\n",
    " - Mary walked the dog who my cat saw in the park\n",
    " - Mary walked the dog who saw my cat in the park\n",
    " \n",
    "Each of these is multiply ambiguous, but you can draw just one tree for each sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 14: Draw trees (at least one tree each) for the sentences above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for the homework.  Feel free to play around with it, there are certainly more things one can do."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
