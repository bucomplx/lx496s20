{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LX 496/796  Introduction -- Poetry, NLTK, and Data Display\n",
    "\n",
    "### Due Monday at 11:59 PM in Gradescope (with grace period of 3 days)\n",
    "\n",
    "In this first homework, you will become familiar with programming in Python on Jupyter Notebooks, and some problem solving while getting familiar with NLTK (the Natural Language Toolkit).\n",
    "\n",
    "Due to how long it took to get this homework distributed, the first part (the haiku generation part) is the only part of this homework that is due Monday night.  The second part, on graphing, will be due as part of the next homework.\n",
    "\n",
    "We will be submitting homeworks (in the form of Jupyter Notebooks) directly to Gradescope; instructions will be provided shortly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Basics \n",
    "\n",
    "A cell in a Python Notebook can be one of two (relevant) types. A Markdown type cell is used for (marked-up) text, and Code type cells are for Python code.  When a cell is selected, its type can be changed by using the Cell Type menu under Cell, or there are shortcuts.\n",
    "\n",
    "Note also that you can be in either edit mode or command mode.\n",
    "If you are in edit mode, you are editing the contents of a cell.\n",
    "You can double-click on cell or hit Enter to enter edit mode on a selected cell.\n",
    "You can press Esc to get to command mode.\n",
    "*Warning*: When you are in command mode, there are a lot of shortcuts activated by pressing a single letter (such as `A` to insert a cell above the current one).  It is super easy to\n",
    "accidentally be in command mode when you meant to be in edit mode and accidentally triggering a bunch of commands.  Be vigilant about what mode you are in.\n",
    "\n",
    "Shift-return will render markdown or execute the code in a cell (depending on the cell type) and advance to the next cell, Ctrl-return will execute the cell but stay there.\n",
    "\n",
    "To see the shortcuts available to you, look at Keyboard Shortcuts under the Help menu.\n",
    "\n",
    "As far the options in Markdown text, the conventions are documented out in the world.  Mostly it is plain text, you can use a few conventions to italicize, bold, make lists.  And HTML markup is also usually processed properly by Markdown.  There is [some documentation here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a markdown cell, and *this is markdown.* That last part looks like `*this is markdown.*` when you edit it, but it rendered as italicized text when you execute this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a code cell, and so here we have a Python comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells are Code by default, but you can change to Markdown using the popup menu at the top of the screen, or by selecting the cell, being in command mode, and typing `M` (for markdown). The shortcut for changing a cell to Code is `Y` (\"Y?\" you ask?  No idea.  \"An enthusiastic **YES!! WE GET TO DO CODE NOW!!**\"? The \"y\" in \"Python\"?).\n",
    "\n",
    "A notebook is really just a collection of code and commentary, and the concept is that you'd run the code in a notebook from the top to the bottom in order.  In practice, when you are working on/in a notebook, you wind up sometimes executing things multiple times, going back up and fixing something, etc. The number to the left indicates what order something has executed in.\n",
    "\n",
    "Also, a notebook keeps track of the output it got when running before, so you do not need to re-run everything to see the result.  When you save it, not just your code input but also your output is preserved.  (Though not external files you used.)\n",
    "\n",
    "Ideally, you should be able to re-run your notebook from top to bottom afterwards.  Choosing \"Restart and Run All\" under \"Kernel\" is a a way to make that happen.  This will render the Markdown cells and execute the Code cells.  If you choose/click Run it will start at the selected cell and run all cells below. You can also Run a cell by selecting it and typing Control-Return (or Shift-Return to execute the cell and then advance the selection to the next cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming in Python\n",
    "\n",
    "Just a couple of quick things to try before we dive in.  You have code in the cells below, which you can run.  Run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"here is a definition\")\n",
    "\n",
    "def sayHi(name):\n",
    "    return \"Hi there, \" + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sayHi(\"Paul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List processing\n",
    "\n",
    "Lists are important, here are some examples.  Run the code, understand why the output says what it says."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1,2,3,4]\n",
    "B = [\"hi\", \"there\", \"Paul\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling stuff out of lists\n",
    "\n",
    "B[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term for a sublist specified that way (with a `:` character) is a \"slice\" in Python.  You are taking a slice of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding, replacing, and finding elements and combining lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.append(\"Hagstron\")\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.index(\"Hagstron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use negative indices to count from the end of a list\n",
    "print(B[3])\n",
    "print(B[-1])\n",
    "print(B[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[3] = \"Hagstrom\"\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = A + B\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B + [\"Last\"])\n",
    "print(B) # we did not change B above, just used it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a kind of a warning/reminder about a case where lists can act in a way that is not entirely intuitive.  Be aware that sometimes copies can be copies of a pointer and not a full copy of a list.  To be sure you have a copy of the contents, you can re-make the list with `list()` or make a copy using `.copy()`.\n",
    "\n",
    "Also handy: `.format()`.  (See also: [Complete documentation of format()](https://docs.python.org/3.4/library/string.html#formatspec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: {}\".format(B))\n",
    "D = B\n",
    "print(\"D: {}\".format(D))\n",
    "B[3] = 'the Octopus'\n",
    "print(\"D: {}\".format(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: {}\".format(B))\n",
    "D = list(B)\n",
    "print(\"D: {}\".format(D))\n",
    "B[3] = 'McCartney'\n",
    "print(\"D: {}\".format(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: {}\".format(B))\n",
    "D = B.copy()\n",
    "print(\"D: {}\".format(D))\n",
    "B[3] = 'Bunyan'\n",
    "print(\"D: {}\".format(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Comprehensions\n",
    "\n",
    "This is perhaps the most useful of the Python constructions we will use.  The \"List comprehension\" is a kind of a specification of a list, usually based on another list.  So, if we had a list containing the numbers 1 to 5, and we wanted to make a new list containing strings like 'Number *n*' for each number, a list comprehension is a compact and elegant way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onefive = [1, 2, 3, 4, 5]\n",
    "numbertext = [\"Number {}\".format(n) for n in onefive]\n",
    "print(numbertext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure is pretty intuitive after you've used them a bit. The first part of the list comprehension is where you build each element, based on a variable that you set after `for` over a range you set with `in`.  And you can also put conditions on which elements you care about. So for a list that has only the odd numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oddnumbertext = ['Odd number {}'.format(n) for n in onefive if n%2 == 1]\n",
    "print(oddnumbertext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Haiku assignment\n",
    "\n",
    "\n",
    "\n",
    "People can argue about this, but let's just say that something will qualify as haiku if it is in three lines, with specific syllable counts: 5-7-5.  Thus:\n",
    "\n",
    "> Haikus are easy\n",
    ">\n",
    "> But sometimes they don't make sense\n",
    ">\n",
    "> Refrigerator\n",
    "\n",
    "(This haiku might be attributable to Rolf Nelson.)\n",
    "\n",
    "So, suppose that we want to use a corpus to create such things.  We need to be able to determine whether we have met the syllable constraints.  Let's do that with the CMU pronunciation corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMU pronunciation corpus has pronunciations for a large set of words, and it is easy to use it with NLTK.  It does not automatically come with NLTK when you install Anaconda, but it is easy to download it.  The first time we go through this, you will want to download it.\n",
    "\n",
    "**Note**: As of January 2020, the graphical interface to the NLTK downloader does not work reliably on the macOS platform.  It is not clear what the issue is.  With the GUI it would be (arguably) easier to download all the corpora, but there are two alternatives that work just fine.  One is to know the name of the corpus that you want to download and just download it by name, like:\n",
    "\n",
    "```python\n",
    "nltk.download('cmudict')\n",
    "```\n",
    "\n",
    "If you do not know the name, or want to see the list and work more interactively, you can explicitly call the non-GUI version by using\n",
    "\n",
    "```python\n",
    "nltk.download_shell()\n",
    "```\n",
    "\n",
    "Here I will suggest using just the corpora we need, by name, but you have both options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line above is how we always want to start, since that makes NLTK available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The download above should get the corpus so we can use it.  It doesn't hurt to do it twice if you do it twice, that just counts as updating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the ways we can look at the CMU pronunciation corpus is in the form of a (Python data type) \"dictionary\", so we'll ask the corpus for that form.  We can also give it a name (`pro`), so that we don't need to type out `cmudict.dict()` all the time.\n",
    "\n",
    "Having done that, we can now look up the pronunciation of a word (like \"trimmed\") in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = cmudict.dict()\n",
    "print(pro['trimmed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for \"trimmed\" above looked a little bit strange because it started with two square brackets.  But this is meaningful and intentional.  The information we wanted (\"how do you pronounce 'trimmed'?\") is represented as a list (an ordered sequence of \"phones\"), starting with a \"T\", followed by an \"R\", followed by an \"IH\" vowel with primary stress, etc.  We know it's a list because it has entries seperated by commas and surrounded by square brackets.  This accounts for the innermost square brackets above, but the outermost brackets also are defining a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 1\n",
    "\n",
    "Find out what you get for `pro['fire']` and then compare it to the output (above) of `pro['trimmed']`. Write down what kind of thing you are getting from `pro[word]` (that is: \"it is a list of...\").\n",
    "\n",
    ">For questions like this there will be a Code cell followed by a Markdown cell.  Put your code in the Code cell and describe what you got (or answer the question) in the Markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1: get the pronunciation for 'fire'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1:** (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 2 \n",
    "\n",
    "Look up \"madelyn\" this way. How many syllables does this word have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2: get the pronunciation for 'madelyn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2:** (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Having just worked that out above, you will have figured out that the coding of the CMU dictionary is such that you can just count the stress marks to know how many syllables a pronunciation has.  We can get the computer to do that for us.  Let's get the computer to do that for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 3 \n",
    "\n",
    "Write a function called `count_syllables()` that, given a word (a string), will look up the pronunciation, count the syllables in the first pronunciation and return the number of syllables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The function takes a word and returns a number of syllables. So it would look abstractly something like this (except with code in the middle lines):\n",
    ">\n",
    ">```python\n",
    ">def count_syllables(word):\n",
    ">    # here, some computation using the word\n",
    ">    # that was passed in, putting the number\n",
    ">    # of syllables into a variable (num_syllables)\n",
    ">    return num_syllables\n",
    ">```\n",
    ">The first thing we are going to need to do is look up the pronunciation of the word that is passed in.  We know from above that when we look up the pronunciations of `word` using `pro[word]`, we get a list.  If we want the first (and often only) pronunciation from that list, we need to focus on the first element.  How do we get the first element of a list? Right. So, the list of phones we are going to check (the first pronunciation) is `pro[word][0]`.\n",
    ">\n",
    ">Each element in this list of phones will look like  `IH1` or `T` or `ZH`.  To figure out how many syllables are in that we need to count how many have a stress mark (that is, ends in a `0`, `1`, or `2`).  How can we get the last letter of an arbitrary string?  Remember that you can use a negative index in a slice in order to count backwards from the end.  The textbook made use of a special function `isdigit()` that we can use here to distinguish digits from non-digits, and that is good enough.  A reasonable strategy here would be to make a list of just those phones with stress marks; the number of syllables would be the length of that list.  This is a good place to use a \"list comprehension\": we want to make a list of `x`es drawn from `pro[word][0]` where (`if`) the last character (`x[-1]`) is a digit (`.isdigit()`).  I'll leave it up to you to compress that into a list comprehension, but it's basically all right there.  And then we want to set `num_syllables` to be the length of that list.\n",
    ">\n",
    ">If you have succeeded, you should get 2 for `count_syllables('fire')`, 5 for `count_syllables('participated')`, 3 for `count_syllables('madelyn')`.\n",
    ">\n",
    ">If you're very concise, you can get this all on one line without using a variable like `num_syllables`, as below. Once you have it working above, you will probably see what I mean.  This is at this point just artistic. The main thing is just to get `count_syllables()` to return the number of syllables, however you do it.\n",
    ">\n",
    ">```python\n",
    ">    return len([x for x in #... etc. \n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3: define and test count_syllables(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We want to construct lines of 5 and 7 syllables.  An easy way to do this is to just pick three words (two that are 5 syllables long, one that is 7 syllables long) and use those.  This would lead to inspired haikus like:\n",
    "\n",
    "```python\n",
    "situational\n",
    "anesthesiology\n",
    "agricultural\n",
    "```\n",
    "\n",
    "But we already know that eventually we are going to want to use smaller words too, such that we might have several words on one line that, together, are five or seven syllables.\n",
    "\n",
    "Minimally, we're going to need to know what the 2 syllable words are, the 3 syllable words, the 4 syllable words, and so forth.  So that when we are trying to complete a line, we know what words are available.\n",
    "\n",
    "We could build each list by saying: go through the list of pronunciations, and pull out the 1 syllable words.  Then, go through the list of pronunciations and pull out the 2 syllable words.  Then the 3 syllable words.  And so forth.\n",
    "\n",
    "But you can see that this means we need to go through all of the pronunciations *seven times* and for each word each time through, compute how many syllables it is so we can see if it matches the number of syllables we're looking for.  If our pronunciation dictionary is very large, this could be a serious amount of wasted work.  We can make this *much* more efficient by setting up seven bins, then going through the words, computing the number of syllables for each word only once, and putting it in the correct bin once we know what the number of syllables is.  (You can see why we would do this if you imagined doing it by hand, or imagine that there are a million words in the pronunciation dictionary and it takes 1 minute per word to compute the number of syllables.  In reality things are much faster and smaller, but that's no real excuse for being grossly inefficient.)\n",
    "\n",
    "So, let's do that, even right now from the outset.\n",
    "\n",
    "Our next task is going to be to go through all of the pronunciations, and build up seven lists (one per number of syllables up to seven) containing words with that number of syllables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 4 \n",
    "\n",
    "Define a function `sort_words(pro)` that will take the pronunciation dictionary and return a list, seven members long, such that the *n*th member of the list (counting from 1) is a list of words that have a pronunciation that is *n* syllables long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This is complex enough that it no longer lends itself to a simple list comprehension.  We want to make a proper function with loops.\n",
    ">\n",
    ">To begin, we'll start with some empty bins, so the skeleton of the function would look like this:\n",
    ">\n",
    ">```python\n",
    ">    def sort_words(pro):\n",
    ">        sorted_words = [[], [], [], [], [], [], []]\n",
    ">        # go through the words in pro\n",
    ">        # drop them into the right bins\n",
    ">        return sorted_words\n",
    ">```\n",
    ">\n",
    ">Then, we go through the words in `pro`.  That loop is pretty simple, so adding it to the skeleton above, we now have:\n",
    ">\n",
    ">```python\n",
    ">    def sort_words(pro):\n",
    ">        sorted_words = [[], [], [], [], [], [], []]\n",
    ">        for w in pro:\n",
    ">            # drop them into the right bins\n",
    ">        return sorted_words\n",
    ">```\n",
    ">\n",
    ">The pronunciations of a word are retrieved with `pro[w]`, and recall this is a list of pronunciations, possibly with more than one.  So we need to go through the pronunciations in `pro[w]`.  Adding that into the skeleton gives us:\n",
    ">\n",
    ">```python\n",
    ">    def sort_words(pro):\n",
    ">        sorted_words = [[], [], [], [], [], [], []]\n",
    ">        for w in pro:\n",
    ">            for p in pro[w]:\n",
    ">                # drop w into bin for syllables in p\n",
    ">        return sorted_words\n",
    ">```\n",
    ">\n",
    ">Now we are at the point where we need to count syllables (that is, stress marks) in the pronunciation `p`.  You can't use the\n",
    "`count_syllables()` function from before because that was looking at only the first pronunciation of a word.  But you can use the same technique.\n",
    ">\n",
    ">Specifically, you can make a list comprehension that will collect together all of the phones in `p` that end in a digit, and then take the `len()` of that list to see how many stress marks (syllables) there were.  If there were 2, then you add the word (`w`) to the bin for 2-syllable words (which is `sorted_words[1]`, keeping in mind that the first bin has index 0).  The way you add `w` to `sorted_words[1]` is: `sorted_words[1].append(w)`.\n",
    ">\n",
    ">In general, you add the word `w` to the bin whose index is the number of syllables in `p` minus 1.  So long as the number of syllables is fewer than 8. \n",
    ">\n",
    ">Because we should leave you with *something* to figure out, this is the part of the function that you can fill in yourself.  It will go in place of the comment in the skeleton developed above, and it will involve counting the number of syllables, checking to see if it is fewer than 8, and adding the word to the list if so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4: define sort_words(pro) returning a list of words organized by syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this function, run the code below.  I got 3924 for the number of 5-syllable words, and 126 for the number of 7-syllable words, that should match what you got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = sort_words(pro)\n",
    "print(len(sorted_words[4]))\n",
    "print(len(sorted_words[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We are now going to write a function that prints terrible haikus, by just choosing 5 and 7 syllables words at random.  In order to get access to Python's random number functions, we need to import them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking a random element from a list is pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AList = ['A','B','C','D','E','F','G','H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALetter = random.choice(AList)\n",
    "print(ALetter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seconds of amusement, you can re-run the cell above a few times (repeatedly press Ctrl-Return) and observe the degree to which it has made a random choice each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 5 \n",
    "\n",
    "Write a function `bad_haiku()` that prints terrible haikus.  Specifically, write a function that will pick two 5 syllable words at random, and one 7 syllable word at random, and print the 7 syllable word between the two 5 syllable words.  Provide a couple of the haikus you generate this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We want to define a function, so this would start like `def bad_haiku():` and it does not need to return anything.  Instead it will just `print()` to the screen.\n",
    ">\n",
    ">Once you have done `import random` then you can make a choice from a list like this:\n",
    ">\n",
    ">```python\n",
    ">x = random.choice(listname)\n",
    ">```\n",
    ">so, to give a relevant example, \n",
    ">\n",
    ">```python\n",
    ">middle_line = random.choice(sorted_words[6])\n",
    ">```\n",
    ">(which should pick a random seven-syllable word).\n",
    ">\n",
    "> So `bad_haiku()`is just going to find a random 5-syllable line, a random 7-syllable line, and another random 5-syllable line, and print them.\n",
    ">\n",
    ">*Note*: You can combine things more concisely, and, rather than finding words first and then printing them, you can print a word as you find it (and thus not need to store the word in a variable), like `print(random.choice(sorted_words[4]))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5: define a bad_haiku() function to print 5-7-5 lines\n",
    "# then execute it a couple of times to print the haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "These are pretty terrible haikus.  It would be nice if at least it would be able to combine some shorter words to make the 5 and 7 syllable lines.  Maybe stylistically, we'd like to keep the last line at a single word, but the others really should be made of shorter words if we're going to convince anyone that we have produced something deep and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start improving our haiku writer.  Let's first try writing it so that instead of producing a 5 syllable word for the first line and a 7 syllable word for the second, it produces a 2-3 / 4-1-2 / 5 pattern.\n",
    "\n",
    "We'll be getting things like this:\n",
    "\n",
    "```python\n",
    "backstage schueneman\n",
    "electrocute cross flagship\n",
    "accommodating\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, if you just use `print(\"something\")`, it will print `something` to the screen, and then move the cursor down to the left (in other words, it prints a return character).  If you want to print something with a customized ending (like a space, or nothing), you can specify this with `end=`. So, observe what happens below.  This will of course be of use when we are printing several words to a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Line one\")\n",
    "print(\"Line two\")\n",
    "print(\"One\", end=' ')\n",
    "print(\"Two\", end=' Pizza time!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 8\n",
    "\n",
    "Define a function `slightly_less_bad_haiku()` that prints randomly chosen words in a 2-3 / 4-1-2 / 5 pattern.  Give a couple of examples of what you get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This will be like the `bad_haiku()` function except with just a bit more printing and finding of words.\n",
    ">\n",
    ">This one you can probably handle on your own without a lot of hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8: define slightly_less_bad_haiku() to print 2-3/4-1-2/5 haikus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "There are a couple of different ways to create a 5 syllable line.  Above we used words of 2, 3, and 5 syllables in a fixed pattern.  But to be more flexible, we could use all kinds of combinations that can add to 5.  It could be five 1-syllable words, it could be 1-2-1-1, or 1-3-1.  There are many options.  And many more options for a 7-syllable line.\n",
    "\n",
    "What we will do next is pick a random word to start a line, and figure out how many syllables that leaves us with, then pick a random word to continue, and repeat.\n",
    "\n",
    "Doing it by hand, it might look like this:\n",
    "\n",
    " - Pick a number from 1 to 7.  We picked 4.\n",
    " - Pick a four syllable word, it turns out to be \"electrocute\".\n",
    " - We are aiming for 7, so we have 3 syllables left to fill.\n",
    "     - Pick a number from 1 to 3. We picked 1.\n",
    "     - Pick a one syllable word, it turns out to be \"cross\".\n",
    "     - We are aiming for 3, so we have 2 syllables left to fill.\n",
    "         - Pick a number from 1 to 2. We picked 2.\n",
    "         - Pick a two syllable word, it turns out to be \"flagship\".\n",
    "         - We have filled our 2 syllables.\n",
    "     - Which means, with \"cross\", we have filled our 3 syllables.\n",
    " - Which means, with \"electrocute\", we have filled our 7 syllables.\n",
    " - Our line is \"electrocute cross flagship\".\n",
    "\n",
    "What we want to do is write a function to do this for us.\n",
    "\n",
    "To illustrate how this could work, we will take a diversion to write a function that will just come up with numbers that add up to some target. Then afterwards, we will revise it to work with words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums_to(total):\n",
    "    new_number = random.randrange(total) + 1\n",
    "    remaining = total - new_number\n",
    "    if remaining == 0:\n",
    "        number_list = [new_number]\n",
    "    else:\n",
    "        number_list = [new_number] + sums_to(remaining)\n",
    "    return number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I use `print(sums_to(7))` three different times, I get \n",
    "#  three different answers, like this:\n",
    "\n",
    "print(sums_to(7))\n",
    "print(sums_to(7))\n",
    "print(sums_to(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way `sums_to` works is a little bit weird (that is to say, it's recursive).  I'll walk through it here, and I'll repeat the line I'm talking about as I talk about it.\n",
    "\n",
    "```python\n",
    "new_number = random.randrange(total) + 1\n",
    "```\n",
    "\n",
    "First it finds a random (integer) number greater than or equal to 0, and less than `total`.  This is accomplished using `random.randrange(total)`.  (`random.randrange()` is like `range()` in that the number you provide is one higher than the function can reach.  So `range(15)` gives a list of numbers from 0 to 14, but not 15; and `random.randrange(15)` could return anything from 0 to 14, but not 15.)  Since we don't want to include 0, we add one, meaning that `new_number` winds up able to be any number from 1 to 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 9\n",
    "\n",
    "Why don't we want to include 0?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 9: (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Ok, continuing on:\n",
    "\n",
    "```python\n",
    "    remaining = total - new_number\n",
    "```\n",
    "\n",
    "This determines how many we have left after our new number before the numbers add up to the `total`.  So, for a `total` of 15, if `new_number` turned out to be 10, then `remaining` would be 5.  That is, we have to find more numbers that add up to 5.\n",
    "\n",
    "```python\n",
    "    if remaining == 0:\n",
    "        number_list = [new_number]\n",
    "```\n",
    "\n",
    "It's possible that we are finished already.  If the number we picked is already as big as the total we are aiming for, then the list we will return (`number_list`) can be just the simple list containing that one number.\n",
    "\n",
    "```python\n",
    "    else:\n",
    "        number_list = [new_number] + sums_to(remaining)\n",
    "```\n",
    "\n",
    "If, on the other hand, we still have more numbers to find, then the list we want to return is one that contains this number (`new_number`) and then some more numbers that add up to `remaining`.  We (will) already have a way to find a list of numbers that add up to `remaining`, it is this very function we are defining now.  So we can return the list containing `new_number` and the numbers that `sums_to(remaining)` finds.\n",
    "\n",
    "```python\n",
    "    return number_list\n",
    "```\n",
    "\n",
    "Then we return the `number_list` we created in one of the two last code fragments.\n",
    "\n",
    "If your brain hurts now, or you suspect witchcraft, welcome to the world of recursive programming.  Even though it seems kind of intuitive if you were doing this yourself as a human, the weird thing about `sums_to` is that in that penultimate line we actually *use the function we are defining as part of its definition.*  Why does this not simply cause the universe to implode?\n",
    "\n",
    "If you actually trace it through and think about what it is doing, it may make a little bit more sense.  Also, it works like the haiku-by-hand example above, really.  But let me try to represent this in a table (below).  The explanation is below the table, but the idea is that as part of computing `sums_to(15)` we need to compute `sums_to(5)` first.  And as part of computing `sums_to(5)` we need to compute `sums_to(2)` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>sums_to(15)\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>picked 10 (5 remain)\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>(find a list that adds to 5)</td>\n",
    "        <td>&rarr; sums_to(5)</td>\n",
    "        <td>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>picked 3 (2 remain)\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>(find a list that adds to 2)</td>\n",
    "        <td>&rarr; sums_to(2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>picked 2 (none remain)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>([2] is such a list])</td>\n",
    "        <td>&larr; return [2]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>([3, 2] is such a list])</td>\n",
    "        <td>&larr; return [3] + [2]</td>\n",
    "        <td>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>&larr; return [10] + [3, 2]<br />a.k.a. [10, 3, 2]</td>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words: We were computing `sums_to(15)`.  We picked a random number, it was **10**.  That by itself does not add to 15.  In addition to the **10**, we need a list of numbers that will add up to the remaining 5.  `sums_to(5)` can find a list with that property.   While computing `sums_to(5)`, we pick a random number, and it was **3**.  That does not add to 5, we also need a list of numbers that will add up to the remaining 2.  So, we call `sums_to(2)` to get such a list.  It randomly picks **2**, which does add up to 2 (that was the goal), so it returns `[2]`, which is a list that adds up to 2.  We can now finish evaluating `sums_to(5)`, which adds the `[3]` it found to the `[2]` it got back, and returns `[3, 2]` (which is a list that adds up to 5).  And then we can finish evaluating `sums_to(15)`, it adds the `[10]` it found to the `[3, 2]` it got back, and returns `[10, 3, 2]` (which is a list that adds to 15).\n",
    "\n",
    "I went through all that because we can use this (pretty directly) to construct a list of words whose syllables add up to five, or seven, or whatever we want.  Really, the only difference between `sums_to()` and the function that we want for our haiku-maker is that instead of making lists of numbers, we want to make lists of words.\n",
    "\n",
    "The next step is to write a function `construct_line(total)` that takes a number of syllables (`total`) and returns a list of words whose syllable lengths add up to the number of syllables passed in.  We're going to base this on `sums_to(total)`.  Before we actually get to the part where you define that function, there are several points to make.\n",
    "\n",
    "The first point is: There's an easy way to do this, since we have `sums_to(total)` already.  We could just do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_construct_line(total):\n",
    "    return [random.choice(sorted_words[n-1]) for n in sums_to(total)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(easy_construct_line(5))\n",
    "print(easy_construct_line(7))\n",
    "print(easy_construct_line(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there is a reason that I don't want to do it quite this way.  The problem is that we are going to (in a little bit) make the choice of the second word be based on the choice of the first word.  We want to make these haikus flow a little bit more naturally.  The idea is that there might be 4 words that often follow the first one, and we want to use one of them as the second word in our haiku.  It shouldn't matter how long they are if they fit, just that they are one of the common continuations.  So instead of picking a length and then looking for a word of that length, it will be better to pick a word out of the set of common continuations and then afterwards look at its length.\n",
    "\n",
    "The line in `sums_to(total)` that is relevant is this one:\n",
    "\n",
    "```python\n",
    "    new_number = random.randrange(total) + 1\n",
    "```\n",
    "\n",
    "What this does is picks a number that is among the possible continuations (since the possible continuations are numbers up to the total amount we are looking for).  To translate this into picking words in a haiku line, we want to pick a word that is among the possible continuations.  That would be any word that has fewer syllables than the total number we are looking for.\n",
    "\n",
    "So let's make a list of the words that are sufficiently short to fit on the rest of the line.  If there are three syllables left, that would include all of the 3-syllable, 2-syllable, and 1-syllable words.  And then we'll just pick one, see how long it was, and then proceed.\n",
    "\n",
    "We already have `sorted_words`, which is a list of words sorted by lengths.  So, `sorted_words[0]` are the 1-syllable words, `sorted_words[1]` are the 2-syllable words, etc.  If we have 2 syllables left on our line, then we want all of the words in *either* `sorted_words[0]` *or* `sorted_words[1]` to be candidates for continuation.  So, let's tranform this `sorted_words` list into one organized by possible continuations.  We can call it `next_words`, and it will be like this: `next_words[0]` is a list of 1-syllable words, the only things you can use if you have only 1 syllable left on the line.  `next_words[1]` is a list of either 1- or 2-syllable words, which are options if you have 2 syllables left on the line.  All of the words in `next_words[0]` are also in `next_words[1]`.\n",
    "\n",
    "To construct `next_words` elegantly is a little bit complicated, so rather than try to get you to write it yourself, I'll provide the function I ended up with and ask you about it.  Below it is defined, and then tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_next_words(sorted_words):\n",
    "    next_words = []\n",
    "    cumulative_words = []\n",
    "    for i in range(7):\n",
    "        word_pairs = [(w, i + 1) for w in sorted_words[i]]\n",
    "        cumulative_words.extend(word_pairs)\n",
    "        next_words.append(list(set(cumulative_words)))\n",
    "    return next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_words = construct_next_words(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sorted_words[0]))\n",
    "print(len(next_words[0]))\n",
    "print(len(sorted_words[1]))\n",
    "print(len(next_words[1]))\n",
    "print(next_words[0][-1])\n",
    "print(next_words[1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 10\n",
    "\n",
    "To show that you understand what `construct_next_words(sorted_words)` is doing, consider the step where `i` is 2.  Describe the list that `word_pairs` gets set to in that iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 10: (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 11\n",
    "\n",
    "Write a function `construct_line(total)` that takes a number of syllables (`total`) as an argument and returns a list of words whose syllables add up to the number of syllables that was passed in.  Use the lists in `next_words` for the source of the random words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As indicated earlier, we are going to model `construct_line(total)` directly on `sums_to(total)`.  The two functions will be almost identical.  The line we want to focus on for changing is the line that, in `sums_to(total)`, reads:\n",
    ">\n",
    ">```python\n",
    ">    new_number = random.randrange(total) + 1\n",
    ">```\n",
    ">\n",
    ">Instead of a random number, we want a random word.  It should be a word that has at most `total` syllables, and now that we have defined `next_words` we can use that.  Specifically, we can find a word that has `total` or fewer syllables by just doing this:\n",
    ">\n",
    ">```python\n",
    ">    new_word_pair = random.choice(next_words[total-1])\n",
    ">```\n",
    ">\n",
    ">The word we picked will be `new_word_pair[0]` and the number of syllables it has will be `new_word_pair[1]`.  So after having picked the word, we will want to determine how many syllables are left by subtracting `new_word_pair[1]` from `total`.\n",
    ">\n",
    ">With that much guidance, define `construct_line(total)` based on `sums_to(total)` but so that it returns a list of words instead of a list of numbers.  You should rename the variables `number_list` and `new_number` to be more sensible for words, like `word_list` and `new_word_pair`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 11: define construct_line(total) to return a list of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If this worked, you should get a couple of (still pretty random) haikus by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(construct_line(5)))\n",
    "print(' '.join(construct_line(7)))\n",
    "print(' '.join(construct_line(5)))\n",
    "print()\n",
    "print(' '.join(construct_line(5)))\n",
    "print(' '.join(construct_line(7)))\n",
    "print(' '.join(construct_line(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These haikus are still pretty terrible.  It's just random words jumbled together.  So, let's take one last step to trying to make these more palatable.  *Spoilers*: they're still going to be terrible.\n",
    "\n",
    "The plan is to use bigrams and conditional frequency distributions to try to chain the words together better, so that as much as possible, the choice of what word comes next is constrained by what has been seen to come next in the corpus.\n",
    "\n",
    "We'll look at the \"romance\" category of the Brown corpus (since this seems most likely to provide poetry). The idea is that we will look at a \"romance\" word, find out how many syllables it has by looking up its pronunciation, and then proceed to the next word based on words that have been seen to follow it in the \"romance\" corpus.  Notice that this means we need to be able to find the \"romance\" word in the pronunciation corpus (because we need to know how many syllables it has).  So, this is only going to work for words that are in both corpora.  Another point about this: The Brown corpus contains some words that are capitalized, but all of the words in the CMU pronunciation corpus are lowercase.  So, as a first step, we will extract the \"romance\" category, and then make it all lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "corp = brown.words(categories='romance')\n",
    "lc_corp = [w.lower() for w in corp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to see what we've done here, let's look at the first 10 words of each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corp[:10])\n",
    "print(lc_corp[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus in lowercase, we can form the bigrams (the pairs of word and next word) using `bigrams(lc_corp)` but then eliminate all of those that contain words we cannot look up in the pronunciation corpus.  So, below, we form `pairs_in_cmu` by going through each bigram `(x,y)` and adding it to the list only when both `x` and `y` are in our pronunciation corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams\n",
    "pairs_in_cmu = [(x,y) for (x,y) in bigrams(lc_corp) if x in pro and y in pro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now. Here is what we want to do. We want to know for any given word (that we can pronounce), what words have been seen to follow that word.  So, this means that we look in our list of bigrams (`pairs_in_cmu`) for everything that has, as its first element, the given word.  The set of observed second elements of those pairs are the words that have been observed following our given word.\n",
    "\n",
    "It might be clearer seeing it in code. The following list comprehension will give us a list of words (that we can pronounce) that have been seen to follow \"angry\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[y for (x,y) in pairs_in_cmu if x == 'angry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we wanted to find a word that follows \"angry\", we could pick one of those words at random. Notice that \"at\" is in there twice, because it was twice observed to follow \"angry\". That's ok, this also gives us the possible benefit that, because it was seen twice as often as any other word, it has twice the chance of any other word of being randomly picked now.\n",
    "\n",
    "It is possible to construct these lists for all of the first elements of the words in `pairs_in_cmu` and then use those lists to decide what to pick next when you are moving through the line of poetry.  However, NLTK already provides a way to do something like this, given its usefulness to language processing tasks.  It is called a \"Conditional Frequency Distribution.\"  It seems a little complicated, but really, it is just a generalization of what we did just above, collecting all the words that follow \"angry\".  You make a conditional frequency distribution with a list of bigrams, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(pairs_in_cmu)\n",
    "cfd['angry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we got just the same result, though this is now a \"frequency distribution\" and so it is counting the number of occurrences.  Since \"at\" occurred twice, it is paired with 2.  In fact, you can tell from the way it is printed, in a kind of key-value format, that you could further ask `cfd['angry']` how often \"at\" occurred, as compared to \"had\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['angry']['at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['angry']['had']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now, the idea is to construct lines where each subsequent word has been seen following the preceding word, hoping that this will increase coherence of our language.  (Notice that this is not being smart at all about how language works, it's just offloading the work to the previously-collected corpus we are relying on.  We assume the corpus put words in a sensible order, so we'll try to mimic that and hope our haiku winds up putting words in a similarly sensible order.)\n",
    "\n",
    "As a way to get started, let's see how we would do this partially by hand.\n",
    "\n",
    "Let's suppose that we start with \"unhappy\" and we are aiming for a line of 5 syllables long.  Since \"unhappy\" is 3 syllables long, we have 2 left.  Let's see what words have been known to follow \"unhappy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['unhappy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which of those are among the options we have in our list of words that we can use if we have 2 syllables left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [(w,s) for (w,s) in next_words[1] if w in cfd['unhappy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we could finish up a 5 syllable line by making it \"unhappy success\".  That sounds moderately poetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to formalize this into a new version of the `construct_line()` function.  I will call it `construct_better_line()` and like before, we need to tell it how many syllables the line should have.  So, it should start *something* like this:\n",
    "\n",
    "```python\n",
    "def construct_better_line(total):\n",
    "```\n",
    "\n",
    "But that's not quite good enough. The `construct_better_line()` function is used each time we need to find a next word, but now the choice of the next word depends on what the previous word was.  So the function needs access to the previous word, not just the target length.  That means that we need to add the previous word as one of the things that the function takes as an argument.  So, really, it should be something like this:\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word):\n",
    "```\n",
    "\n",
    "But if we're just starting a line at the beginning, there is no previous word.  Python has a special value for things that don't exist, called `None`.  We can set up this function with a \"default\" for the `previous_word` such that, if no previous word is provided, it is assumed to be `None`. Like so:\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "```\n",
    "\n",
    "This means there are two situations to consider, one where we have a previous word (we are in the middle of a line), and one where we don't (we are at the beginning of a line).  If there is no previous word, the choice of the next word is relatively unconstrained, we can just pick a random word (that has fewer than `total` syllables).  If there is a previous word, then we need to consult the conditional frequency distribution we built from the bigrams.  You can test for whether `previous_word` is `None` or not by treating `previous_word` as if it were a True/False value.  `None` will evaluate as `False`, anything else will evaluate as `True`.\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "    if previous_word:\n",
    "        # select the next word based on the previous one\n",
    "    else:\n",
    "        # select the first word however we like\n",
    "```\n",
    "\n",
    "Let's start with what happens if we are at the beginning of a line.  I demonstrated this above by starting with \"unhappy\".  Can you just pick any random word?  Well, let's see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 12\n",
    "\n",
    "How many different words can follow \"linda\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 12: How many different words can follow \"linda\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 12**: (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 13\n",
    "\n",
    "One of the words that can follow \"linda\" is \"socially\".  So we know that \"socially\" is in both corpora.  How many different words can follow \"socially\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 13: How many different words can follow \"socially\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 13**: (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "It is not guaranteed that there will be continuations available from any word you pick.  It might be that there simply are no examples in the corpus of words following the word you picked, or it might be that all of the examples there are have too many syllables to fit on what's left of your line.  We will probably need to deal with this contingency, but at least when we are starting a line, we want to pick a word that has somewhere to go.\n",
    "\n",
    "So, let's make a list of good starting words.  The plan is to find the 100 words with the highest number of possible following words, and when we start a new line, we will pick one of those.  This doesn't really address the issue directly, but it's a fairly easy way to give the haiku generator a fighting chance.\n",
    "\n",
    "We need to know for each word how many continuations it has.  Recall that above we discovered that \"unhappy\" has 4 continuations.  We can get this number directly by taking the length of the frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['unhappy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cfd['unhappy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's compute this for every word in `cfd`.  We can make that list as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_next = [(len(cfd[x]), x) for x in cfd]\n",
    "num_next[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sort this, it will sort it by the first element in the pair, which is what we want.  This is sorting it in order of number of continuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_next = sorted(num_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_next[:3]) # least continuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_next[-3:]) # most continuable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words with the most continuations are at the end (it sorts from low to high), and so the 100 \"most continuable\" words would be `sorted_next[-100:]`.  Let's assume that we are not going to want to choose among those most continuable words based on differences in their continuability, and transform the list so it contains just the words (not the continuation).  In other words, we want to do a list comprehension that extracts just the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_starts = [w for (n, w) in sorted_next[-100:]]\n",
    "print(good_starts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting back to what happens at the beginning of a line in `construct_better_line`, we want to pick one of those \"good starts\" as the next word if there is no previous word.  It is possible that some of those words have too many syllables, though.  It's not really likely, but we should still take that into account.  So, we need to filter the list so that it just has words that have fewer than `total` syllables, and then make a random choice from among those.\n",
    "\n",
    "The simplest way to do this is to filter the options list by whether each is in `good_starts`.  Recall that built the `options` list for \"unhappy\" before like this:\n",
    "\n",
    "```python\n",
    "options = [(w,s) for (w,s) in next_words[1] if w in cfd['unhappy']]\n",
    "```\n",
    "\n",
    "We will still want that form for when we are continuing from a word, but the task at hand is to continue when there was no previous word.  So we filter on whether the word is a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 7 # we aim to construct a line of length 7\n",
    "options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we embed this into the function we are building up, we wind up with this:\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "    if previous_word:\n",
    "        # select the next word based on the previous one\n",
    "    else:\n",
    "        # select the first word however we like\n",
    "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
    "```\n",
    "\n",
    "Thinking ahead, we can expect that the block that executes if we have a previous word will also provide a list of options for the next word, so let's add something outside the conditional that will pick one of the options as the next word.\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "    if previous_word:\n",
    "        # select the next word based on the previous one\n",
    "    else:\n",
    "        # select the first word however we like\n",
    "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
    "    word = random.choice(options)\n",
    "```\n",
    "\n",
    "And now we need to determine whether we are done, or whether we need to get more words.  The choice of `word` is a pair, where the first element is the word and the second element is its length.  So it is relatively easy to see if we are done.  If we reached `total`, just return what we have.  If we have a ways to go, we return what we have so far and what `construct_better_line` gives us for the remaining syllables.\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "    if previous_word:\n",
    "        # select the next word based on the previous one\n",
    "    else:\n",
    "        # select the first word however we like\n",
    "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
    "    word = random.choice(options)\n",
    "    remaining = total - word[1]\n",
    "    line = [word[0]]\n",
    "    if remaining > 0:\n",
    "        line += construct_better_line(remaining, word[0])\n",
    "    return line\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That has covered the case where we had no previous word.  We can now turn our attention to what happens when `construct_better_line()` is called with a previous word.  In that case, we need to figure out what the possible continuations are from that word, filter them down to just those that do not have too many syllables, and pick one of them.\n",
    "\n",
    "We were just reminded above of how we find the continuation options from a single word (as we did sort of by hand for \"unhappy\").  Now is the time to deploy that.  We know how many syllables remain (so we know which available continuations to draw from), and we have the word (so we know where to look in `cfd`).  And the structure of the function we are building allows us to just set `options` in the conditional, and use the rest of the function as it is already written.  So:\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "    if previous_word:\n",
    "        # select the next word based on the previous one\n",
    "        options = [(w,s) for (w,s) in next_words[total-1] if w in cfd[previous_word]]\n",
    "```\n",
    "\n",
    "And that is almost it.  Assuming you followed the discussion above, you should be able to assemble it into the full definition of `construct_better_line()`.  There is just one case left that we should consider:\n",
    "\n",
    "It is possible that no following word is found at all.  Recall how many words followed \"socially\".  If we wind up adding \"socially\" to a line with syllables left to go, we can't continue.  So we need to decide what to do.  The simplest thing is just to say that if there is nowhere to go, pick a new start from among the good starts.\n",
    "\n",
    "This leads me/us to a slight reorganization of the structure in order to allow fractionally more elegance.  We will set a flag `continuing` to be, by default, false.  This indicates whether we are continuing from a prior word.  If there is a previous word and we find a continuation, then we set this flag to true.  Then, if we are not continuing (meaning either that there was no previous word, or there was one but it didn't provide any options), we pick a new word from among our good starts.\n",
    "\n",
    ">Note: there is a failure case that is not being considered here, which is if there are no good starts that are short enough for the number of syllables that are left.  Because \"a\" is for sure in our good starts, this won't arise.  However, if the good starts list is further filtered in a way that could leave it with no 1-syllable words, this could come up.\n",
    "\n",
    "```python\n",
    "def construct_better_line(total, previous_word = None):\n",
    "    continuing = False\n",
    "    if previous_word:\n",
    "        # select the next word based on the previous one\n",
    "        options = [(w,s) for (w,s) in next_words[total-1] if w in cfd[previous_word]]\n",
    "        if len(options) > 0:\n",
    "            continuing = True            \n",
    "    if not continuing:\n",
    "        # select the first word however we like\n",
    "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
    "```\n",
    "\n",
    "Ok, now you have all the pieces to assemble `construct_better_line()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 14.\n",
    "\n",
    "Define `construct_better_line()` as described above, such that it (where possible) will pick from words it has seen following the current word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 14: Define construct_better_line(total, previous_word = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If it worked, the following should provide some haikus that, frankly, are still terrible.  But maybe have a little bit of flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(' '.join(construct_better_line(5)))\n",
    "    print(' '.join(construct_better_line(7)))\n",
    "    print(' '.join(construct_better_line(5)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways this could be improved.  This homework has taken almost long enough.  Just one more thing to try, and this might be mildly difficult.  These poems were based on the \"romance\" genre portion of the Brown corpus.  But the Brown corpus has several other genres.  The command below will list them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back up to where we first defined `corp` as being `brown.words(categories='romance')`.  And then we defined `lc_corp` as the lowercased words.  And then we defined `pairs_in_cmu` to filter those down to just the words we have pronunciations for.  And defined `cfd` as a conditional frequency distribution of those words.  Then defined `num_next` as being a list of how many continuations each word has, and sorted it into `sorted_next` and then built `good_starts` from that.\n",
    "\n",
    "If you were to retrace those steps after defining `corp` to draw words from the \"science_fiction\" genre instead, how might our haikus change?\n",
    "\n",
    "In the end, you need to wind up with `good_starts`, `next_words`, and `cfd` defined for the corpus before `construct_better_line()` will use the new corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 15\n",
    "\n",
    "Produce a couple of haikus based on the word sequencing in the \"science_fiction\" genre within the Brown corpus, and comment on how they seem to differ or not from the ones we build with the \"romance\" genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 15: retrace the steps from corpus to haiku to make \"science_fiction\" haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 15**. (markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
